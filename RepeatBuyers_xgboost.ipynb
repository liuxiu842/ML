{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepeatBuyers_xgboost.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1ZoCDiQmAiDKqQAQ1t-RZlbHDFQkQvbvM",
      "authorship_tag": "ABX9TyPwEnB5mp1k+UAzxpycu6lD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuxiu842/ML/blob/master/RepeatBuyers_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBP3wDXqJnsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import gc\n",
        "import pandas as pd\n",
        "# 用户行为，使用format1进行加载\n",
        "# 加载全量样本\n",
        "\"\"\"\n",
        "user_log = pd.read_csv('./data_format1/user_log_format1.csv', dtype={'time_stamp':'str'})\n",
        "user_info = pd.read_csv('./data_format1/user_info_format1.csv')\n",
        "train_data1 = pd.read_csv('./data_format1/train_format1.csv')\n",
        "submission = pd.read_csv('./data_format1/test_format1.csv')\n",
        "\"\"\"\n",
        "# 加载小样本\n",
        "user_log = pd.read_csv('/content/drive/My Drive/Colab Notebooks/L11/data_format1_small/sample_user_log.csv', dtype={'time_stamp':'str'})\n",
        "user_info = pd.read_csv('/content/drive/My Drive/Colab Notebooks/L11/data_format1_small/sample_user_info.csv')\n",
        "train_data1 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/L11/data_format1_small/train.csv')\n",
        "submission = pd.read_csv('/content/drive/My Drive/Colab Notebooks/L11/data_format1_small/test.csv')\n",
        "#train_data = pd.read_csv('./data_format2/train_format2.csv')\n",
        "\n",
        "train_data1['origin'] = 'train'\n",
        "submission['origin'] = 'test'\n",
        "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)\n",
        "#print(matrix)\n",
        "\n",
        "matrix.drop(['prob'], axis=1, inplace=True)\n",
        "# 连接user_info表，通过user_id关联\n",
        "matrix = matrix.merge(user_info, on='user_id', how='left')\n",
        "# 使用merchant_id（原列名seller_id）\n",
        "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\n",
        "# 格式化\n",
        "user_log['user_id'] = user_log['user_id'].astype('int32')\n",
        "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\n",
        "user_log['item_id'] = user_log['item_id'].astype('int32')\n",
        "user_log['cat_id'] = user_log['cat_id'].astype('int32')\n",
        "user_log['brand_id'].fillna(0, inplace=True)\n",
        "user_log['brand_id'] = user_log['brand_id'].astype('int32')\n",
        "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')\n",
        "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\n",
        "matrix['age_range'].fillna(0, inplace=True)\n",
        "# 0:female, 1:male, 2:unknown\n",
        "matrix['gender'].fillna(2, inplace=True)\n",
        "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
        "matrix['gender'] = matrix['gender'].astype('int8')\n",
        "matrix['label'] = matrix['label'].astype('str')\n",
        "\n",
        "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
        "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
        "del user_info, train_data1\n",
        "gc.collect()\n",
        "print(matrix)\n",
        "\n",
        "# User特征处理\n",
        "groups = user_log.groupby(['user_id'])\n",
        "# 用户交互行为数量 u1\n",
        "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
        "#temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
        "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "\n",
        "# 时间间隔特征 u6 按照小时\n",
        "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
        "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
        "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
        "# 统计操作类型为0，1，2，3的个数\n",
        "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "#print(matrix)\n",
        "\n",
        "# 商家特征处理\n",
        "groups = user_log.groupby(['merchant_id'])\n",
        "# 商家被交互行为数量 m1\n",
        "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
        "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
        "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
        "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
        "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
        "# 统计商家被交互的action_type 唯一值\n",
        "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
        "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
        "# 按照merchant_id 统计随机负采样的个数\n",
        "# temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
        "# matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
        "#print(matrix)\n",
        "\n",
        "# 按照user_id, merchant_id分组\n",
        "groups = user_log.groupby(['user_id', 'merchant_id'])\n",
        "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
        "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
        "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
        "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
        "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
        "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔\n",
        "#print(matrix)\n",
        "\n",
        "#用户购买点击比\n",
        "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
        "#商家购买点击比\n",
        "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
        "#不同用户不同商家购买点击比\n",
        "matrix['r3'] = matrix['um7']/matrix['um5']\n",
        "matrix.fillna(0, inplace=True)\n",
        "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
        "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
        "matrix = pd.concat([matrix, temp], axis=1)\n",
        "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
        "matrix = pd.concat([matrix, temp], axis=1)\n",
        "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
        "\n",
        "print(matrix)\n",
        "\n",
        "# 分割训练数据和测试数据\n",
        "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
        "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
        "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
        "\n",
        "print(train_y)\n",
        "del temp, matrix\n",
        "gc.collect()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI2LiIQ8etRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 使用机器学习工具\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "# 将训练集进行切分，20%用于验证\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2)\n",
        "\n",
        "# 使用XGBoost\n",
        "model = xgb.XGBClassifier(\n",
        "    max_depth=10,\n",
        "    n_estimators=500,\n",
        "    min_child_weight=300, \n",
        "    colsample_bytree=0.8, \n",
        "    subsample=0.8, \n",
        "    eta=0.3,    \n",
        "    seed=42    \n",
        ")\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_metric='auc', eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "    verbose=True,\n",
        "    #早停法，如果auc在10epoch没有进步就stop\n",
        "    early_stopping_rounds=10 \n",
        ")\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "prob = model.predict_proba(test_data)\n",
        "submission['prob'] = pd.Series(prob[:,1])\n",
        "submission.drop(['origin'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izfzYt62iAjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "#import catboost as cat\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score\n",
        "from sklearn.tree import export_graphviz\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu-4jdrepxJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_roc_curve(fprs, tprs):\n",
        "    \n",
        "    tprs_interp = []\n",
        "    aucs = []\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    f, ax = plt.subplots(figsize=(8, 8))\n",
        "    \n",
        "    # Plotting ROC for each fold and computing AUC scores\n",
        "    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n",
        "        tprs_interp[-1][0] = 0.0\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        aucs.append(roc_auc)\n",
        "        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC Fold {} (AUC = {:.3f})'.format(i, roc_auc))\n",
        "        \n",
        "    # Plotting ROC for random guessing\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random Guessing')\n",
        "    \n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "    \n",
        "    # Plotting the mean ROC\n",
        "    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n",
        "    \n",
        "    # Plotting the standard deviation around the mean ROC Curve\n",
        "    std_tpr = np.std(tprs_interp, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n",
        "    \n",
        "    ax.set_xlabel('False Positive Rate', size=15, labelpad=20)\n",
        "    ax.set_ylabel('True Positive Rate', size=15, labelpad=20)\n",
        "    ax.tick_params(axis='x', labelsize=15)\n",
        "    ax.tick_params(axis='y', labelsize=15)\n",
        "    ax.set_xlim([-0.05, 1.05])\n",
        "    ax.set_ylim([-0.05, 1.05])\n",
        "\n",
        "    ax.set_title('ROC Curves of Folds', size=20, y=1.02)\n",
        "    ax.legend(loc='lower right', prop={'size': 13})\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK8779Dxp2Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_feature_importances(feature_importances, title, feature_names):\n",
        "    feature_importances = 100.0*(feature_importances/max(feature_importances))\n",
        "    index_sorted = np.flipud(np.argsort(feature_importances))\n",
        "    pos = np.arange(index_sorted.shape[0])+0.5\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(16,4))\n",
        "    plt.bar(pos,feature_importances[index_sorted])\n",
        "    for tick in ax.get_xticklabels():\n",
        "        tick.set_rotation(90)\n",
        "    plt.xticks(pos,feature_names[index_sorted])\n",
        "    plt.ylabel('Relative Importance')\n",
        "    plt.title(title)\n",
        "    plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiIBCiy-qTzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = train_y\n",
        "train = train_X\n",
        "train, X_valid, target, y_valid = train_test_split(train_X, train_y, test_size=.5)\n",
        "test = test_data\n",
        "print(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl86kjtCqxis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_optimizer_params(model, model_params, train=train, test=test):\n",
        "    gridsearch = GridSearchCV(model, model_params, scoring='roc_auc', cv=5)\n",
        "    gridsearch.fit(train, target)\n",
        "    best_score = gridsearch.best_score_\n",
        "    print(\"Best score: %0.3f\" % best_score)\n",
        "    print(\"Best parameters set:\")\n",
        "    best_parameters = gridsearch.best_estimator_.get_params()\n",
        "    for param_name in sorted(gridsearch.param_grid.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "#     print(best_parameters)\n",
        "    return best_parameters\n",
        "\n",
        "def get_model_result(model, model_params, model_name, scaler=None, test_size=0.5, train=train, test=test, feature_importance=False, gridsearch=True):\n",
        "    if scaler is not None:\n",
        "        train = scaler.fit_transform(train)\n",
        "        test = scaler.fit_transform(test)\n",
        "\n",
        "    if gridsearch is True:\n",
        "        best_params = get_optimizer_params(model, model_params)\n",
        "        model.set_params(**best_params)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=test_size, random_state=2020, stratify=target)\n",
        "    model.fit(X_train, y_train)\n",
        "    prob_y_val = model.predict_proba(X_val)[:,1] if hasattr(model, 'predict_proba') else model.predict(X_val)\n",
        "    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_val, prob_y_val)\n",
        "    best_score = auc(trn_fpr, trn_tpr)\n",
        "    best_parameters = model.get_params()\n",
        "    plot_roc_curve([list(trn_fpr)], [list(trn_tpr)])\n",
        "        \n",
        "        \n",
        "    if feature_importance is True:\n",
        "        plot_feature_importances(model.feature_importances_, 'Importance of Features', train.columns)\n",
        "    result = pd.DataFrame()\n",
        "    result['user_id'] = user_id\n",
        "    result['Attrition'] = pd.DataFrame(model.predict_proba(test)[:,1] if hasattr(model, 'predict_proba') else model.predict(test))\n",
        "    result[['user_id', 'Attrition']].to_csv(f'result-{model_name}.csv', index=False, float_format='%.8f')\n",
        "    print('result of predict:\\n', result.head())\n",
        "    return best_score, best_parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykHNE0M8qzIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([train, test]).corr() ** 2\n",
        "data = np.tril(data, k=-1)\n",
        "data[data==0] = np.nan\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf1Qt0iWq8bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "figure, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(np.sqrt(data), annot=False, cmap='viridis', ax=ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn3VZ-narG9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = train.corrwith(target).agg('square')\n",
        "\n",
        "figure, ax = plt.subplots(figsize=(10, 10))\n",
        "data.agg('sqrt').plot.bar(ax=ax)\n",
        "del data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcD_f4xmrT2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Ridge()\n",
        "model_params = {'alpha': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 7], 'tol': [0.0001, 0.001, 0.01, 0.1]}\n",
        "model_params = {'alpha': [2], 'tol': [0.0001]}\n",
        "start = time.time()\n",
        "best_score_ridge, best_params_ridge = get_model_result(model, model_params, 'ridge', StandardScaler())\n",
        "print(time.time()-start)\n",
        "print('best_score_ridge,', best_score_ridge)\n",
        "print('best_params_ridge,', best_params_ridge)\n",
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8xRHXaBrlFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Lasso()\n",
        "model_params = {'alpha': np.logspace(-10, -6, 50)}\n",
        "model_params = {'alpha': [1e-10]}\n",
        "print(model_params)\n",
        "start = time.time()\n",
        "best_score_lasso, best_params_lasso = get_model_result(model, model_params, 'lasso', StandardScaler())\n",
        "print(time.time() - start)\n",
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M_keyL6rtWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ElasticNet()\n",
        "model_params = {'alpha': np.logspace(-10, -4, 10), 'l1_ratio': np.logspace(-10, -4, 10)}\n",
        "#model_params = {'alpha': [0.0001], 'l1_ratio': [1e-10]}\n",
        "start = time.time()\n",
        "best_score_elasticnet, best_params_elasticnet = get_model_result(model, model_params, 'elasticnet', StandardScaler())\n",
        "print(time.time() - start)\n",
        "del model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XtJoqMRsPFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LogisticRegression(class_weight='balanced')\n",
        "model_params = {\n",
        "    'penalty': ['l1', 'l2'], \n",
        "    'C': [0.4, 0.5, 0.6],\n",
        "    'solver':['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga']\n",
        "    }\n",
        "# model_params = {\n",
        "#     'penalty': ['l1'], \n",
        "#     'C': [0.5],\n",
        "#     'solver':['liblinear']\n",
        "# }\n",
        "start = time.time()\n",
        "best_score_lgr,best_params_lgr = get_model_result(model, model_params,'logisticregression', StandardScaler()) \n",
        "print(time.time() - start)\n",
        "del model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei8ls2L51JMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC()\n",
        "model_params = {\n",
        "    'C':[0.1,1,5,10,50,100, 200],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma':[1,0.1,0.01,0.001]\n",
        "}\n",
        "best_score_svc, best_params_svc = get_model_result(model, model_params, 'SVC', StandardScaler())\n",
        "del model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bglrxDwlM5Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = xgb.XGBClassifier(random_state=2020,tree_method='gpu_hist', silent=1, booster='gbtree', objective='binary:logistic')\n",
        "model_params = {\n",
        "    'booster':['gbtree'],\n",
        "    'colsample_bytree': [0.5, 0.8],\n",
        "    'subsample': [0,3, 0.5],\n",
        "    'learning_rate': [0.075, 0.01],\n",
        "    'objective': ['binary:logistic'],\n",
        "    'max_depth': [ 7, 8, 9],\n",
        "    'num_parallel_tree': [0.1, 1, 10],\n",
        "    'min_child_weight': [0.2, 0.8],\n",
        "}\n",
        "# model_params = {\n",
        "#     'colsample_bytree': [0.5],\n",
        "#     'subsample': [0.5],\n",
        "#     'learning_rate': [0.075],\n",
        "#     'max_depth': [9],\n",
        "#     'num_parallel_tree': [1],\n",
        "#     'min_child_weight': [0.2],\n",
        "# }\n",
        "\n",
        "start = time.time()\n",
        "best_score_xgboost, best_params_xgboost = get_model_result(model, model_params, 'xgboost')\n",
        "print(time.time()-start)\n",
        "del model  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpcCsDbZSto-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DecisionTreeClassifier(random_state=2020)\n",
        "model_params = {\n",
        "    'max_features': [0.8, 1.0], \n",
        "    'max_depth': [8, 9, 10],\n",
        "    'min_samples_leaf':[30, 40, 50]\n",
        "} \n",
        "# model_params = {\n",
        "#     'max_features': [1.0], \n",
        "#     'max_depth': [9],\n",
        "#     'min_samples_leaf':[30]\n",
        "# }\n",
        "start = time.time()\n",
        "best_score_dtc, best_params_dtc = get_model_result(model, model_params, 'dtc', None, feature_importance=True)\n",
        "print(time.time() - start)\n",
        "del model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAliNwK4Ts8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RandomForestClassifier(random_state=2020)\n",
        "model_params = {\n",
        "    'n_estimators':[500],\n",
        "    'n_jobs':[-1],\n",
        "    'max_features': [0.5, 0.6], \n",
        "    'max_depth': [8, 9, 10],\n",
        "    'min_samples_leaf':[8, 10],\n",
        "#     'random_state':[2020]\n",
        "}\n",
        "model_params = {\n",
        "    'n_estimators':[200],\n",
        "    'max_features': [0.6], \n",
        "    'max_depth': [10],\n",
        "    'min_samples_leaf':[10],\n",
        "}\n",
        "start = time.time()\n",
        "best_score_rfc, best_params_rfc = get_model_result(model, model_params, 'rfc', feature_importance=True)\n",
        "print(time.time() - start)\n",
        "del model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gti0Q8FcUOcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lgb.LGBMClassifier(random_state=2020, device='gpu', gpu_platform_id=0, gpu_device_id=0, silent=1)\n",
        "model_params = {\n",
        "    'n_estimators': [200, 300, 400],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'num_leaves':[10,100,400],\n",
        "    'colsample_bytree':[0.5,0.8, 1.0],\n",
        "    'subsample':[0.3,0.5,0.9],\n",
        "    'max_depth':[7, 10, 15],\n",
        "    'reg_alpha':[0.01, 0.2, 0.5],\n",
        "    'reg_lambda':[0.01, 0.3, 0.8],\n",
        "    'min_split_gain':[0.01, 0.1],\n",
        "    'min_child_weight': [1,2,4],\n",
        "}\n",
        "start = time.time()\n",
        "best_score_lightgbm, best_params_lightgbm = get_model_result(model, model_params, 'lightgbm')\n",
        "print(time.time()-start)\n",
        "del model "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}